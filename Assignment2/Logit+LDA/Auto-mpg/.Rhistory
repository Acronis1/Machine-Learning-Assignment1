pred<-predict(model_lda_full, newdata = test)
model_lda_full<-lda(mpg~horsepower+weight+modelYear+origin, data=train)
pred<-predict(model_lda_full, newdata = test)
new<-cbind(test['id'],pred)
test$horsepower=as.numeric(test$horsepower)
pred<-predict(model_lda_full, newdata = test)
new<-cbind(test['id'],pred)
write.csv(new, file = "solution1_lda1.csv",quote=FALSE,row.names=FALSE)
pred
pred$class
new<-cbind(test['id'],pred$class)
write.csv(new, file = "solution1_lda1.csv",quote=FALSE,row.names=FALSE)
model_lda_full<-lda(log(mpg)~horsepower+weight+modelYear+origin, data=train)
test$mpg=log(test$mpg)
test$mpg=as.numeric(test$mpg)
View(test)
model_lda_full<-lda(log(mpg)~horsepower+weight+modelYear+origin, data=train)
pred<-exp(predict(model_lda_full, newdata = test))
pred<-predict(model_lda_full, newdata = test)
new<-cbind(test['id'],exp(pred$class))
new<-cbind(test['id'],exp(as.numeric(pred$class)))
write.csv(new, file = "solution1_lda1.csv",quote=FALSE,row.names=FALSE)
new<-cbind(test['id'],as.numeric(pred$class))
train$mpg=log(train$mpg)
model_lda_full<-lda(mpg~horsepower+weight+modelYear+origin, data=train)
pred<-predict(model_lda_full, newdata = test)
pred$class
exp(pred$class)
exp(as.numeric(pred$class))
?log
?exp
exp(as.numeric(pred$class), base=exp(1))
exp(1)
exp(log(2.7182))
log(2.7182)
train<-read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Auto-mpg/AutoMPG.shuf.train.csv",header=TRUE)
train<-train[ , -which(names(train) %in% c("carName"))]
train=na.mean(train)
train$horsepower=as.numeric(train$horsepower)
#lets do something with glm():
?glm
model_glm_log=glm(mpg~., data=train, family = "bionmial")
model_glm_log=glm(mpg~., data=train, family = "binomial")
model_glm_log=glm(mpg~., data=train, family = "poisson")
pred<-predict(model_lda_full, newdata = test)
pred<-predict(model_glm_log, newdata = test)
pred
exp(pred)
pred<-predict(model_glm_log, newdata = test)
new<-cbind(test['id'],exp(pred))
write.csv(new, file = "solution1_lda1.csv",quote=FALSE,row.names=FALSE)
write.csv(new, file = "solution1_glm_log.csv",quote=FALSE,row.names=FALSE)
model_glm_log=glm(mpg~., data=train, family = "quasibinomial")
model_glm_log=glm(mpg~., data=train, family = "quasipoisson")
pred<-predict(model_glm_log, newdata = test)
new<-cbind(test['id'],exp(pred))
write.csv(new, file = "solution1_glm_quasilog.csv",quote=FALSE,row.names=FALSE)
#using a trimmed not overfitting model:
model_glm_log=glm(mpg~horsepower+weight+modelYear+origin, data=train, family = "quasipoisson")
pred<-predict(model_glm_log, newdata = test)
new<-cbind(test['id'],exp(pred))
write.csv(new, file = "solution1_glm_log_notfull.csv",quote=FALSE,row.names=FALSE)
library(rpart)
library(caret)
library(plyr)
library(ISLR)
library(splines)
library(mgcv)
library(dplyr)
library(imputeTS)
library(MASS)
library(DAAG)
set.seed(123)
train<-read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/KDD-cup/cup98ID.shuf.5000.train.csv",header=TRUE)
test<-read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/KDD-cup/cup98ID.shuf.5000.test.csv",header=TRUE)
View(test)
train=na.mean(train, option = "mean")
test=na.mean(test, option = "mean")
train=train[, sapply(train, function(col) length(unique(col))) > 1]
test=test[, sapply(test, function(col) length(unique(col))) > 1]
train <- train[,colSums(is.na(train))<nrow(train)]
test <- test[,colSums(is.na(test))<nrow(test)]
train <- mutate_all(train, function(x) as.numeric(as.character(x)))
test <- mutate_all(test, function(x) as.numeric(as.character(x)))
model_glm_log=glm(TARGET_D  ~.-CONTROLN , data=train, family = "poisson")
model_glm_log=lm(log(TARGET_D)  ~.-CONTROLN , data=train)
train <- train[,colSums(is.na(train))<nrow(train)]
train <- train[,colSums(is.na(train))<nrow(train)]
test <- test[,colSums(is.na(test))<nrow(test)]
model_glm_log=lm(log(TARGET_D)  ~.-CONTROLN , data=train)
train$TARGET_D
train$TARGET_D=train$TARGET_D+1
model_glm_log=lm(log(TARGET_D)  ~.-CONTROLN , data=train)
pred<-predict(model_glm_log, newdata = test)
colnames(test)[which(names(test) == "ADATE_22")] <- "ADATE_2"
pred<-predict(model_glm_log, newdata = test)
#variable selection
res = lm(TARGET_D~.,data=train, na.action = na.exclude)
res=stepAIC(res, direction="backward")
res=step(res, direction="backward")
res=step(TARGET_D~1, direction="forward", scope=c(res))
res=step(TARGET_D~1, direction="forward", scope=c(1,res))
?step
res = lm(TARGET_D~.,data=train, na.action = na.exclude)
summary(res)
View(train)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(TARGET_D~., data=train, method="lvq", preProcess="scale", trControl=control)
# train the model
?train
model <- train(TARGET_D~., data=train, method="lvq", preProcess="scale", trControl=control, na.action=na.omit)
model <- train(TARGET_D~., data=train, method="logicBag", preProcess="scale", trControl=control, na.action=na.omit)
model <- train(TARGET_D~., data=train, method="glmnet", preProcess="scale", trControl=control, na.action=na.omit)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
model_glm_log=glm(log(TARGET_D)  ~.-CONTROLN , data=train)
?glm
model_glm_log=glm((TARGET_D)~ETH13+LSC2+ETH5+OCC6+LFC7+EIC8+OCC5+EIC9+ETH15+ANC8+ETH16+EC7+HHAS2+EC3, data=train, method="possion")
model_glm_log=glm((TARGET_D)~ETH13+LSC2+ETH5+OCC6+LFC7+EIC8+OCC5+EIC9+ETH15+ANC8+ETH16+EC7+HHAS2+EC3, data=train, method="poisson")
model_glm_log=glm((TARGET_D)~ETH13+LSC2+ETH5+OCC6+LFC7+EIC8+OCC5+EIC9+ETH15+ANC8+ETH16+EC7+HHAS2+EC3, data=train, family="poisson")
pred<-predict(model_glm_log, newdata = test)
new<-cbind(test['CONTROLN '],pred-1)
new<-cbind(test['CONTROLN'],pred-1)
write.csv(new, file = "solution1_glm_kdd.csv",quote=FALSE,row.names=FALSE)
train$TARGET_D
new$`pred - 1`[new$`pred - 1` < 0] <- 0
write.csv(new, file = "solution1_glm_kdd.csv",quote=FALSE,row.names=FALSE)
model_lda<-lda((TARGET_D)~ETH13+LSC2+ETH5+OCC6+LFC7+EIC8+OCC5+EIC9+ETH15+ANC8+ETH16+EC7+HHAS2+EC3, data=train)
new<-cbind(test['CONTROLN'],pred-1)
new$`pred - 1`[new$`pred - 1` < 0] <- 0
new$`pred - 1`=exp(new$`pred - 1`)
write.csv(new, file = "solution1_ldakdd.csv",quote=FALSE,row.names=FALSE)
pred<-predict(model_lda_full, newdata = test)
model_lda<-lda((TARGET_D)~ETH13+LSC2+ETH5+OCC6+LFC7+EIC8+OCC5+EIC9+ETH15+ANC8+ETH16+EC7+HHAS2+EC3, data=train)
pred<-predict(model_lda_full, newdata = test)
model_lda<-lda((TARGET_D)~ETH13+LSC2+ETH5+OCC6+LFC7+EIC8+OCC5+EIC9+ETH15+ANC8+ETH16+EC7+HHAS2+EC3, data=train)
pred<-predict(model_lda, newdata = test)
new<-cbind(test['CONTROLN'],pred-1)
new$`pred - 1`=exp(new$`pred - 1`)
new$`pred - 1`[new$`pred - 1` < 0] <- 0
pred
pred-1
as.numeric(pred)-1
as.factor(pred)-1
new<-cbind(test['CONTROLN'],pred)
model_lda<-lda((TARGET_D)~ETH13+LSC2+ETH5+OCC6+LFC7+EIC8+OCC5+EIC9+ETH15+ANC8+ETH16+EC7+HHAS2+EC3, data=train)
pred<-predict(model_lda, newdata = test)
new<-cbind(test['CONTROLN'],pred)
new$pred=exp(new$pred)
new$pred[new$pred < 0] <- 0
model_lda<-lda((TARGET_D)~ETH13+LSC2+ETH5+OCC6+LFC7+EIC8+OCC5+EIC9+ETH15+ANC8+ETH16+EC7+HHAS2+EC3, data=train)
pred<-predict(model_lda, newdata = test)
new<-cbind(test['CONTROLN'],pred$class-1)
pred$class
pred$class-1
as.numeric(pred$class)-1
model_lda<-lda((TARGET_D)~ETH13+LSC2+ETH5+OCC6+LFC7+EIC8+OCC5+EIC9+ETH15+ANC8+ETH16+EC7+HHAS2+EC3, data=train)
pred<-predict(model_lda, newdata = test)
new<-cbind(test['CONTROLN'],as.numeric(pred$class)-1)
write.csv(new, file = "solution1_ldakdd.csv",quote=FALSE,row.names=FALSE)
as.numeric(pred$class)-1
write.csv(new, file = "solution1_ldakdd.csv",quote=FALSE,row.names=FALSE)
data<-read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Air_quality/AirQualityUCI.csv", header=TRUE)
data<-read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Air_quality/AirQualityUCI.csv", header=TRUE, sep=";")
View(data)
data2=data[data$CO.GT. == -200] <- NA
data2=data[data == -200] <- NA
data2=data[, 3:3][data[, 3:3] == -200] <- NA
data2=data[, 3][data[, 3] == -200] <- NA
data2=na_if(data, -200)
Mif
?if
)
data$CO.GT.==NA
data = data[ , -which(names(data) %in% c("X","X.1"))]
if (data$CO.GT.==-200) {
data$CO.GT.==NA
}
library(caret)
library(plyr)
library(rpart)
library(caret)
library(plyr)
library(ISLR)
library(splines)
library(mgcv)
library(dplyr)
library(imputeTS)
library(MASS)
library(DAAG)
set.seed(123)
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Air_quality/AirQualityUCI.csv", header=TRUE, sep=";")
data = data[ , -which(names(data) %in% c("X","X.1"))]
if (data$CO.GT.==-200) {
data$CO.GT.=NA
}
na_if(data, -200)
View(data)
data=na_if(data, -200)
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Air_quality/AirQualityUCI.csv", header=TRUE, sep=";")
data = data[ , -which(names(data) %in% c("X","X.1"))]
data=na_if(data, -200)
data=na.mean(data)
install.packages("imputeTS")
library(imputeTS)
data=na.mean(data)
data=na_if(data, "")
data=na.mean(data)
data=data[!is.na(data$CO.GT.),]
smp_size <- floor(0.8 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train<-data[train_ind,]
test<-data[-train_ind,]
plot(train)
#it is visible that date, time T, Ah, RH have no correlation with our label, let's omit them:
data = data[ , -which(names(data) %in% c("T","RH","AH","Date","Time"))]
smp_size <- floor(0.8 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train<-data[train_ind,]
test<-data[-train_ind,]
model_glm_log=glm(CO.GT.~., data=train, family = "poisson")
#building logit model:
?glm
model_glm_log=glm(CO.GT.~., data=train, family = "poisson", na.action=na.exclude)
data=na_if(data, -200)
data=na_if(data, -200.0)
data$CO.GT.[data$CO.GT. == -200] <- NA
data$CO.GT=data$CO.GT.[data$CO.GT. == -200] <- NA
data$CO.GT=data$CO.GT.[data$CO.GT. == -200.0] <- NA
data$CO:GT. <- revalue(data$CO:GT., c(-200.0=NA))
data$CO:GT. <- revalue(data$CO.GT., c(-200.0=NA))
data$CO.GT. <- revalue(data$CO.GT., c(-200.0=NA))
data$CO.GT. <- revalue(data$CO.GT., c(-200.0,NA))
data$CO.GT.[data$CO.GT. %in% -200] <- NA
data$CO.GT.[data$CO.GT. %in% -200.0] <- NA
data$CO.GT.[data$CO.GT. %in% "-200.0"] <- NA
View(data)
sapply(data, typeof)
data$CO.GT.[data$CO.GT. == -200] <- NA
data$CO.GT.[data$CO.GT. == -200.0] <- NA
data<-data[!(data$CO.GT.==-200 ,]
data<-data[!(data$CO.GT.==-200 ]
data<-data[!(data$CO.GT.==-200) ]
data<-data[!(data$CO.GT.==-200), ]
data<-data[!(data$PT08.S1.CO.==-958), ]
data<-data[!(data$PT08.S1.CO.==-958.0), ]
library(rpart)
library(caret)
library(plyr)
library(ISLR)
library(splines)
library(mgcv)
library(dplyr)
library(imputeTS)
library(MASS)
library(DAAG)
set.seed(123)
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Air_quality/AirQualityUCI.csv", header=TRUE, sep=";")
data = data[ , -which(names(data) %in% c("X","X.1"))]
data=na_if(data, -200)
data=na_if(data, "")
data<-data[!(data$PT08.S1.CO.==-958.000), ]
data=na_if(data, -200.0)
data <- mutate_all(data, function(x) as.numeric(as.character(x)))
data$CO.GT.=as.numeric(data$CO.GT.)
data=na_if(data, -200.0)
View(data)
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Air_quality/AirQualityUCI.csv", header=TRUE, sep=";")
View(data)
data = data[ , -which(names(data) %in% c("X","X.1"))]
data$CO.GT.=as.numeric(data$CO.GT.)
data=na_if(data, -200.0)
data=na_if(data, "")
sapply(data, typeof)
data=na.mean(data)
data=na_if(data, -200.0)
data=na_if(data, -200)
data$C6H6.GT.=as.numeric(data$C6H6.GT.)
data=na_if(data, -200)
data=na_if(data, 2)
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Air_quality/AirQualityUCI.csv", header=TRUE, sep=";")
data = data[ , -which(names(data) %in% c("X","X.1"))]
data$CO.GT.=as.numeric(data$CO.GT.)
data$C6H6.GT.=as.numeric(data$C6H6.GT.)
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Air_quality/AirQualityUCI.csv", header=TRUE, sep=";")
data = data[ , -which(names(data) %in% c("X","X.1"))]
data=na_if(data, -200)
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Air_quality/AirQualityUCI.csv", header=TRUE, sep=";")
data = data[ , -which(names(data) %in% c("X","X.1"))]
data$CO.GT.=as.numeric(data$CO.GT.)
data$C6H6.GT.=as.numeric(data$C6H6.GT.)
data=na_if(data, -200)
data=na_if(data, 2)
data=na_if(data, "")
data=na.mean(data)
#I don't want to fill in missing labels, it would probably introduce bias, still we have 7765
#observations, it should be sufficient.
data=data[!is.na(data$CO.GT.),]
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Air_quality/AirQualityUCI.csv", header=TRUE, sep=";")
data = data[ , -which(names(data) %in% c("X","X.1"))]
data$CO.GT.=as.numeric(data$CO.GT.)
data$C6H6.GT.=as.numeric(data$C6H6.GT.)
data=na_if(data, -200)
data=na_if(data, 2)
data=na_if(data, "")
sapply(data, typeof)
#I don't want to fill in missing labels, it would probably introduce bias, still we have 7765
#observations, it should be sufficient.
data=data[!is.na(data$CO.GT.),]
#filling in with means.
data=na.mean(data)
#it is visible that date, time T, Ah, RH have no correlation with our label, let's omit them:
data = data[ , -which(names(data) %in% c("T","RH","AH","Date","Time"))]
smp_size <- floor(0.8 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train<-data[train_ind,]
test<-data[-train_ind,]
#building logit model:
?glm
model_glm_log=glm(CO.GT.~., data=train, family = "poisson", na.action=na.exclude)
pred_glm<-predict(model_glm_log, newdata = test)
#let's calculate the RMSE:
rmse_log = sqrt(mean((pred_glm-test$CO.GT.)^2))
rmse_log
model_lda<-lda(CO.GT.~., data=train)
pred_lda<-predict(model_lda, newdata = test)
rmse_lda = sqrt(mean((pred_lda-test$CO.GT.)^2))
rmse_lda = sqrt(mean((pred_lda$class-test$CO.GT.)^2))
rmse_lda
pred_lda$class
pred_lda<-predict(model_lda, newdata = test)$class
pred_lda<-as.numeric(predict(model_lda, newdata = test)$class)
rmse_lda = sqrt(mean((pred_lda-test$CO.GT.)^2))
rmse_lda
rmse_log
#basic feature selection:
linmod=lm(CO.GT.~., data=train)
linmod=stepAIC(linmod, direction="backward")
summary(linmod)
model_glm_log_red=glm(CO.GT.~PT08.S1.CO.+NMHC.GT.+PT08.S2.NMHC.+NOx.GT., data=train, family = "poisson", na.action=na.exclude)
summary(model_glm_log_red)
summary(linmod)
model_glm_log_red=glm(CO.GT.~PT08.S1.CO.+NMHC.GT.+PT08.S2.NMHC.+NOx.GT.+PT08.S3.NOx.+NO2.GT.+PT08.S4.NO2.+PT08.S5.O3., data=train, family = "poisson", na.action=na.exclude)
summary(model_glm_log_red)
pred_glm_red<-predict(model_glm_log_red, newdata = test)
#let's calculate the RMSE:
rmse_log_red = sqrt(mean((pred_glm_red-test$CO.GT.)^2))
rmse_log_red
rmse_log
model_lda<-lda(CO.GT.~PT08.S1.CO.+NMHC.GT.+PT08.S2.NMHC.+NOx.GT.+PT08.S3.NOx.+NO2.GT.+PT08.S4.NO2.+PT08.S5.O3., data=train)
pred_lda<-as.numeric(predict(model_lda, newdata = test)$class)
rmse_lda = sqrt(mean((pred_lda-test$CO.GT.)^2))
rmse_lda
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Breast_cancer/wpbc.data", header=FALSE, sep=",")
View(data)
colnames(data) <- c("id","label")
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Breast_cancer/wpbc.data", header=FALSE, sep=",")
colnames(data)
colnames(data)[0]
colnames(data)[1]
colnames(data)[1] = "id"
colnames(data)[2] = "label"
colnames()data
colnames(data)
data=na.mean(data)
data=na_if(data, '?')
data=na.mean(data)
data[,35]
data[,35] = as.numeric(data[,35])
data=na.mean(data)
plot(data)
#splitting data into train and test:
par("mar")
par(mar=c(1,1,1,1))
plot(data)
par("mar")
par(mar=c(5.1,4.1,4.1,2.1))
par("mar")
graphics.off()
plot(data)
plot(data)
plot(data)
plot(data)
plot(data)
windows()
plot(data)
dev.off()
windows()
plot(data)
smp_size <- floor(0.8 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train<-data[train_ind,]
test<-data[-train_ind,]
model_glm_log=glm(label~., data=train, family = "poisson", na.action=na.exclude)
data$label=as.numeric(data$label)
model_glm_log=glm(label~., data=train, family = "poisson", na.action=na.exclude)
sapply(data, class)
data$V3=as.factor(data$V3)
model_glm_log=glm(label~., data=train, family = "poisson", na.action=na.exclude)
model_glm_log=glm(label~.-id, data=train, family = "poisson", na.action=na.exclude)
#based on the high number of atriutes, let's do feature selection:
linmod=lm(label~., data=train)
linmod=stepAIC(linmod, direction="backward")
data = data.matrix(data)
model_glm_log=glm(label~.-id, data=train, family = "poisson", na.action=na.exclude)
sapply(data, class)
model_glm_log=glm(label~.-id, data=train+1, family = "poisson", na.action=na.exclude)
model_glm_log=glm(label~.-id, data=train+2, family = "poisson", na.action=na.exclude)
train2=train+1
View(train2)
View(train)
model_glm_log=glm(label~.-id, data=train, family = "poisson", na.action=na.exclude)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train<-data[train_ind,]
test<-data[-train_ind,]
View(train)
model_glm_log=glm(label~.-id, data=train, family = "poisson", na.action=na.exclude)
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Breast_cancer/wpbc.data", header=FALSE, sep=",")
colnames(data)[1] = "id"
colnames(data)[2] = "label"
data$label=as.numeric(data$label)
data$V3=as.factor(data$V3)
data=na_if(data, '?')
data[,35] = as.numeric(data[,35]) #column 35 was not numeric
data=na.mean(data)
smp_size <- floor(0.8 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train<-data[train_ind,]
test<-data[-train_ind,]
#based on the high number of atriutes, let's do feature selection:
linmod=lm(label~., data=train)
linmod=stepAIC(linmod, direction="backward")
summary(linmod)
model_glm_log=glm(label~.-id, data=train, family = "poisson", na.action=na.exclude)
pred_glm<-predict(model_glm_log, newdata = test)
pred_glm<-predict(model_glm_log, newdata = test, type="response")
?predict.glm
pred_glm<-predict(model_glm_log, newdata = test, type="terms")
pred_glm<-predict.glm(model_glm_log, newdata = test, type="terms")
model_glm$xlevels[["V3"]] <- union(model_glm$xlevels[["V3"]], levels(test$V3))
model_glm_log$xlevels[["V3"]] <- union(model_glm_log$xlevels[["V3"]], levels(test$V3))
pred_glm<-predict.glm(model_glm_log, newdata = test, type="terms")
pred_glm<-predict.glm(model_glm_log, newdata = test, type="response")
#let's calculate the RMSE:
rmse_log = sqrt(mean((pred_glm-test$CO.GT.)^2))
rmse_log
pred_glm
pred_glm<-predict.glm(model_glm_log, newdata = test)
#let's calculate the RMSE:
rmse_log = sqrt(mean((pred_glm-test$CO.GT.)^2))
rmse_log
pred_glm
model_log=lm(log(label)~.-id, data=train, na.action=na.exclude)
pred_log<-exp(predict(model_log, newdata = test))
summary(model_log)
model_log=lm(label~.-id, data=train, na.action=na.exclude)
summary(model_log)
model_log=lm(label~.-id, data=data, na.action=na.exclude)
summary(model_log)
#let's calculate the RMSE:
rmse_log = sqrt(mean((pred_glm-test$label)^2))
rmse_log
pred_glm
model_log=lm(label~.-id, data=data, na.action=na.exclude)
pred_log<-exp(predict(model_log, newdata = test))
pred_log
#let's calculate the RMSE:
rmse_log = sqrt(mean((pred_log-test$label)^2))
rmse_log
model_lda<-lda(label~., data=train)
linmod=lm(label~., data=train)
linmod=stepAIC(linmod, direction="backward")
summary(linmod)
model_lda<-lda(label~.-id, data=train)
linmod=lm(label~., data=train)
summary(linmod)
data <- read.csv("C:/Users/goso/Desktop/házifeladatok/Machine Learning/assignment2/Breast_cancer/wpbc.data", header=FALSE, sep=",")
colnames(data)[1] = "id"
colnames(data)[2] = "label"
data$label=as.numeric(data$label)
data$V3=as.numeric(data$V3)
data=na_if(data, '?')
data[,35] = as.numeric(data[,35]) #column 35 was not numeric
data=na.mean(data)
smp_size <- floor(0.8 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train<-data[train_ind,]
test<-data[-train_ind,]
#based on the high number of atriutes, let's do feature selection:
linmod=lm(label~., data=train)
linmod=stepAIC(linmod, direction="backward")
summary(linmod)
model_log=lm(label~.-id, data=data, na.action=na.exclude)
pred_log<-exp(predict(model_log, newdata = test))
summary(model_log)
pred_log
#let's calculate the RMSE:
rmse_log = sqrt(mean((pred_log-test$label)^2))
rmse_log
#here are the singificant attributes:
summary(linmod)
model_lda<-lda(label~V3+V4+V5+V7+V8+V13+V15+V16+V17+V19+V20+V24+V29+V30+V31+V34+V35, data=train)
pred_lda<-as.numeric(predict(model_lda, newdata = test)$class)
rmse_lda = sqrt(mean((pred_lda-test$CO.GT.)^2))
rmse_lda
rmse_lda = sqrt(mean((pred_lda-test$label)^2))
rmse_lda
